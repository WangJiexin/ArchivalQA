{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntactic & Temporal Filtering/Transforming Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fd99c4cd950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Syntactic_Temporal_Processing:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_ent_num: int, \n",
    "        max_ent_num: int, \n",
    "        min_token_num: int, \n",
    "        max_token_num: int, \n",
    "    ):\n",
    "        self.min_ent_num = min_ent_num\n",
    "        self.max_ent_num = max_ent_num\n",
    "        self.min_token_num = min_token_num\n",
    "        self.max_token_num = max_token_num\n",
    "        \n",
    "    def __call__(self, raw_results_df):\n",
    "        self.results_df = raw_results_df\n",
    "        self.remove_que_without_qmark()\n",
    "        self.remove_que_ansinquestion()\n",
    "        self.remove_que_duplicate()\n",
    "        self.add_nlp_column()\n",
    "        self.remove_que_entissue()\n",
    "        self.remove_que_tokissue()\n",
    "        return self.results_df\n",
    "    \n",
    "    def add_nlp_column(self):\n",
    "        self.results_df['que_nlp'] = self.results_df['question'].apply(lambda x: nlp(x))\n",
    "        \n",
    "    def remove_que_without_qmark(self):\n",
    "        #1. Remove questions that do not end with a question mark.\n",
    "        self.results_df = self.results_df[self.results_df['question'].str.endswith('?')]\n",
    "        self.results_df = self.results_df.reset_index(drop=True)\n",
    "        \n",
    "    def remove_que_ansinquestion(self):\n",
    "        #2. Remove questions whose answers are explicitly indicated inside the questionsâ€™ content.\n",
    "        self.results_df = self.results_df[self.results_df.apply(lambda x: x[\"answer\"].lower() not in x[\"question\"].lower(), axis=1)]\n",
    "        self.results_df = self.results_df.reset_index(drop=True)\n",
    "        \n",
    "    def remove_que_duplicate(self):\n",
    "        #3. Remove duplicate questions.\n",
    "        self.results_df = self.results_df[~self.results_df.duplicated('question',keep=False)]\n",
    "        self.results_df = self.results_df.reset_index(drop=True)\n",
    "        \n",
    "    def remove_que_entissue(self):\n",
    "        #4. Remove questions that have too few or too many named entities.\n",
    "        removed_index = []\n",
    "        for row_i,row in self.results_df.iterrows():\n",
    "            if min_ent_num<=len(row['que_nlp'].ents)<=max_ent_num:\n",
    "                continue\n",
    "            else:\n",
    "                removed_index.append(row_i)\n",
    "        self.results_df = self.results_df.drop(removed_index).reset_index(drop=True)\n",
    "    \n",
    "    def remove_que_tokissue(self):\n",
    "        #5. Remove questions that are too short or too long.\n",
    "        removed_index = []\n",
    "        for row_i,row in self.results_df.iterrows():\n",
    "            if min_token_num<=len(row['que_nlp'])<=max_token_num:\n",
    "                continue\n",
    "            else:\n",
    "                removed_index.append(row_i)\n",
    "        self.results_df = self.results_df.drop(removed_index).reset_index(drop=True)\n",
    "    \n",
    "    def remove_que_pronissue(self):\n",
    "        #6. Remove questions with unclear pronouns\n",
    "        pass #(TBD)\n",
    "    \n",
    "    def transform_que_temp(self):\n",
    "        #7. Transform relative temporal information in questions to absolute temporal information.\n",
    "        pass #(TBD)\n",
    "    \n",
    "    def transform_ans_temp(self):\n",
    "        #8. Transform relative temporal information of the answers of generated questions to absolute temporal information.\n",
    "        pass #(TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "example=pickle.load(open(\"data/examples.pickle\", \"rb\"))\n",
    "\n",
    "raw_results_df=feather.read_feather(\"data/raw_results_After_2ndModule.feather\")\n",
    "print(len(raw_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ent_num,max_ent_num = 1,7\n",
    "min_token_num,max_token_num = 8,30\n",
    "ST_Processing = Syntactic_Temporal_Processing(min_ent_num,max_ent_num,min_token_num,max_token_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "basic_filtered_results_df = ST_Processing(raw_results_df)\n",
    "print(len(basic_filtered_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_filtered_results_df[\"org_answer\"] = basic_filtered_results_df[\"answer\"]\n",
    "basic_filtered_results_df[\"trans_que\"] = \"\"\n",
    "basic_filtered_results_df[\"trans_ans\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_filtered_results_df = basic_filtered_results_df[[\"question\",\"answer\",\"org_answer\",\"ans_pos\",\"ans-sent_pos\",\"para_id\",\"trans_que\",\"trans_ans\"]]\n",
    "basic_filtered_results_df.to_feather(\"data/raw_results_After_3rdModule.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
